{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "civil-columbia",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "exempt-aluminum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'K_Y': 'KY', 'T_Y': 'TY', 'G_Y': 'GY', 'S_Y': 'SY', 'SH_Y': 'SHY', 'B_Y': 'BY', 'P_Y': 'PY', 'N_Y': 'NY', 'M_Y': 'MY', 'V_Y': 'VY', 'L_Y': 'LY', 'F_Y': 'FY', 'D_Y': 'DY', 'HH_Y': 'HHY'}\n",
      "{'KY': 1, 'TY': 1, 'GY': 1, 'SY': 1, 'SHY': 1, 'BY': 1, 'PY': 1, 'NY': 1, 'MY': 1, 'VY': 1, 'LY': 1, 'FY': 1, 'DY': 1, 'HHY': 1}\n",
      "{'KY': 'C', 'TY': 'C', 'GY': 'C', 'SY': 'C', 'SHY': 'C', 'BY': 'C', 'PY': 'C', 'NY': 'C', 'MY': 'C', 'VY': 'C', 'LY': 'C', 'FY': 'C', 'DY': 'C', 'HHY': 'C'}\n"
     ]
    }
   ],
   "source": [
    "### some special characters that need to be specially treated, made a dict for them\n",
    "\n",
    "# These are the half size katakana character that need to be attached to their preceding characters \n",
    "hankaku=['ャ','ュ','ョ','ァ','ィ','ゥ','ェ','ォ','ッ']\n",
    "\n",
    "# These are the consonants that are usually treated as 1 consonants in Japanese\n",
    "# Therefore, the \"_\" is removed between these two consonants\n",
    "# The second dictionary asigned a length of 1 to each of them\n",
    "# The 3rd dictionary assigned a \"C\"(single consonant) value to each of them\n",
    "Dcons=['K_Y','T_Y','G_Y','S_Y','SH_Y','B_Y','P_Y','N_Y','M_Y','V_Y','L_Y','F_Y','D_Y','HH_Y']\n",
    "dcs=[]\n",
    "for i in Dcons:\n",
    "    j=re.sub(\"_\", \"\", i)\n",
    "    dcs.append(j)\n",
    "ddc=dict(zip(Dcons, dcs))\n",
    "print(ddc)\n",
    "tp1=[]\n",
    "for i in range(0, len(dcs)):\n",
    "    tp1.append(1)\n",
    "Dupdate1=dict(zip(dcs, tp1))\n",
    "print(Dupdate1)\n",
    "tp2=[]\n",
    "for i in range(0, len(dcs)):\n",
    "    tp2.append(\"C\")\n",
    "Dupdate2=dict(zip(dcs, tp2))\n",
    "print(Dupdate2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "short-desert",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### read the katakana word list(after annoted) and save into lists\n",
    "\n",
    "full_w=[] # contains the full entry in the word list: katakana, English, pronunciation\n",
    "w_pr=[] # contains the pronunciations only\n",
    "ka_w=[] # contains the katakana words only\n",
    "with open(\"JMdata/JM_annotB2.tsv\", \"r\", encoding=\"utf-8\") as ed:\n",
    "    for l in ed:\n",
    "        ll=l.rstrip().split(\"\\t\")\n",
    "#         s_len.append(len(ll[0]))\n",
    "        full_w.append(ll)\n",
    "        ka_w.append(ll[0])\n",
    "        w_pr.append(ll[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "arbitrary-teens",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15174\n",
      "['アードバーク', 'アバカス', 'アバクス', 'アブダクション', 'アベンド', 'アーベント', 'アビリティー', 'アブノーマル', 'アブノーマルエンド', 'アボリジニ']\n",
      "15174\n",
      "[['アードバーク', 'aardvark', 'AA1_R_D_V_AA2_R_K'], ['アバカス', 'abacus', 'AE1_B_AH0_K_AH0_S'], ['アバクス', 'abacus', 'AE1_B_AH0_K_AH0_S'], ['アブダクション', 'abduction', 'AE0_B_D_AH1_K_SH_AH0_N'], ['アベンド', 'abend', 'AE1_B_EH0_N_D'], ['アーベント', 'abend', 'AE1_B_EH0_N_D'], ['アビリティー', 'ability', 'AH0_B_IH1_L_AH0_T_IY2'], ['アブノーマル', 'abnormal', 'AE0_B_N_AO1_R_M_AH0_L'], ['アブノーマルエンド', 'abnormal|end', 'AE0_B_N_AO1_R_M_AH0_L|EH1_N_D'], ['アボリジニ', 'aborigine', 'AE2_B_ER0_IH1_JH_AH0_N_IY0']]\n"
     ]
    }
   ],
   "source": [
    "print(len(ka_w))\n",
    "# print(ka_w[:10])\n",
    "print(len(w_pr))\n",
    "# print(full_w[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "precise-darkness",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### First step: change the format of dounble consonants\n",
    "\n",
    "w_p=[]\n",
    "for i in w_pr:\n",
    "    for j in ddc:\n",
    "        if j in i:\n",
    "            i=re.sub(j, ddc[j], i)\n",
    "    w_p.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "emotional-filter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15174\n",
      "['AH0_B_Z_AO1_R_B_ER0', 'AE0_B_S_T_R_AE1_K_T', 'AE0_B_S_T_R_AE1_K_SH_AH0_N', 'AE1_B_UW0|D_AA1_B_IY0', 'AH0_BY_UW1_S', 'AH0_BY_UW1_S', 'AE0_B_S_IH1_N_IY2_AH0|JH_AE1_K_AH0_L', 'AE0_B_S_IH1_N_IY2_AH0_N', 'AH0_K_EY1_SH_AH0', 'AH0_K_EY1_SH_AH0']\n"
     ]
    }
   ],
   "source": [
    "print(len(w_p))\n",
    "# print(w_p[20:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "portable-excess",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########get indext of hankaku char\n",
    "# len_w1=[]\n",
    "# for i in len_w:\n",
    "#     ii=[]\n",
    "#     ii.append(i[1])\n",
    "#     inds=[]\n",
    "#     for j in hankaku:\n",
    "#         ind=i[1].find(j)\n",
    "#         if ind != -1:\n",
    "#             inds.append(ind)\n",
    "#     ii.append(inds)\n",
    "#     lens=len(i[1])-len(inds)\n",
    "#     ii.append(lens)\n",
    "#     len_w1.append(ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "rental-sodium",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(len_w1))\n",
    "# print(len_w1[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "engaged-sailing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(s_len))\n",
    "# print(len(w_p))\n",
    "# print(w_p[:10])\n",
    "# print(s_len[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "greatest-essex",
   "metadata": {},
   "outputs": [],
   "source": [
    "### the \"cmu_kt.csv\" file contains 3 columns: Symbols appear in CMU dict; The length of each symbol(1 length); Their phonological values(either C, or V)\n",
    "ctl1=[]\n",
    "ctl2=[]\n",
    "ctl3=[]\n",
    "with open(\"cmu_kt.csv\", \"r\", encoding=\"utf-8\") as ct:\n",
    "    for i in ct:\n",
    "        ii=i.rstrip().split(\",\")\n",
    "        ctl1.append(ii[0])\n",
    "        ctl2.append(int(ii[1]))\n",
    "        ctl3.append(ii[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "working-ceramic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n",
      "61\n",
      "61\n",
      "['V', 'V', 'V', 'V', 'V', 'V', 'V', 'V', 'V', 'V', 'V', 'V', 'V', 'V', 'V', 'V', 'V', 'V', 'V', 'V', 'V', 'V', 'V', 'V', 'V', 'V', 'V', 'V', 'V', 'V', 'V', 'V', 'V', 'V', 'V', 'V', 'V', 'V', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ctl_lend=dict(zip(ctl1, ctl2))\n",
    "ctl_lend=dict(zip(ctl1, ctl2))\n",
    "print(len(ctl1))\n",
    "print(len(ctl2))\n",
    "\n",
    "print(len(ctl3))\n",
    "# print(ctl3)\n",
    "ctl_patd=dict(zip(ctl1, ctl3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "civic-banks",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AA0': 1, 'AA1': 1, 'AA2': 1, 'AE0': 1, 'AE1': 1, 'AE2': 1, 'AH0': 1, 'AH1': 1, 'AH2': 1, 'IH0': 1, 'IH1': 1, 'IH2': 1, 'UH0': 1, 'UH1': 1, 'UH2': 1, 'OW0': 1, 'OW1': 1, 'OW2': 1, 'U': 1, 'W0': 1, 'W1': 1, 'W2': 1, 'AO0': 1, 'AO1': 1, 'AO2': 1, 'A': 1, 'Y0': 1, 'Y1': 1, 'Y2': 1, 'EH0': 1, 'EH1': 1, 'EH2': 1, 'E': 1, 'R0': 1, 'R1': 1, 'R2': 1, 'I': 1, 'O': 1, 'B': 1, 'CH': 1, 'D': 1, 'DH': 1, 'F': 1, 'G': 1, 'HH': 1, 'JH': 1, 'K': 1, 'L': 1, 'M': 1, 'N': 1, 'P': 1, 'R': 1, 'S': 1, 'SH': 1, 'T': 1, 'TH': 1, 'V': 1, 'W': 1, 'Y': 1, 'Z': 1, 'ZH': 1, 'KY': 1, 'TY': 1, 'GY': 1, 'SY': 1, 'SHY': 1, 'BY': 1, 'PY': 1, 'NY': 1, 'MY': 1, 'VY': 1, 'LY': 1, 'FY': 1, 'DY': 1, 'HHY': 1}\n",
      "75\n"
     ]
    }
   ],
   "source": [
    "#### make 2 dictioanries from the 3 lists above; one maps the symbols to length, one maps the symbols to phonological values\n",
    "\n",
    "ctl_lend.update(Dupdate1)\n",
    "ctl_patd.update(Dupdate2)\n",
    "print(ctl_lend)\n",
    "print(len(ctl_patd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "sticky-discount",
   "metadata": {},
   "outputs": [],
   "source": [
    "### seperate the dipthongs to two symbols becuase in Japanese they usually represented by 2 characters\n",
    "\n",
    "dpthn={'AW0':['A','W0'], 'AW1':['A','W1'], 'AW2':['A','W2'],\n",
    "       'AY0':['A','Y0'], 'AY1':['A','Y1'], 'AY2':['A','Y2'],\n",
    "       'ER0':['E','R0'], 'ER1':['E','R1'], 'ER2':['E','R2'],\n",
    "       'EY0':['E','Y0'], 'EY1':['E','Y1'], 'EY2':['E','Y2'],\n",
    "       'IY0':['I','Y0'], 'IY1':['I','Y1'], 'IY2':['I','Y2'],\n",
    "       'UW0':['U','W0'], 'UW1':['U','W1'], 'UW2':['U','W2'],\n",
    "       'OY0':['O','Y0'], 'OY1':['O','Y1'], 'OY2':['O','Y2'],\n",
    "       'OW0':['O','W0'], 'OW1':['O','W1'], 'OW2':['O','W2'],\n",
    "       'NG':['N','G']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "large-sessions",
   "metadata": {},
   "outputs": [],
   "source": [
    "### preprocessing the pronunciations\n",
    "\n",
    "pr=[]\n",
    "for i in w_p:\n",
    "    ii=i.split(\"|\")\n",
    "    iii=[]\n",
    "    for j in ii:\n",
    "        jj=j.split(\"_\")\n",
    "        iii.append(jj)\n",
    "    pr.append(iii)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "transparent-marijuana",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15174\n",
      "[[['AA1', 'R', 'D', 'V', 'AA2', 'R', 'K']], [['AE1', 'B', 'AH0', 'K', 'AH0', 'S']], [['AE1', 'B', 'AH0', 'K', 'AH0', 'S']], [['AE0', 'B', 'D', 'AH1', 'K', 'SH', 'AH0', 'N']], [['AE1', 'B', 'EH0', 'N', 'D']], [['AE1', 'B', 'EH0', 'N', 'D']], [['AH0', 'B', 'IH1', 'L', 'AH0', 'T', 'IY2']], [['AE0', 'B', 'N', 'AO1', 'R', 'M', 'AH0', 'L']], [['AE0', 'B', 'N', 'AO1', 'R', 'M', 'AH0', 'L'], ['EH1', 'N', 'D']], [['AE2', 'B', 'ER0', 'IH1', 'JH', 'AH0', 'N', 'IY0']]]\n"
     ]
    }
   ],
   "source": [
    "print(len(pr))\n",
    "# print(pr[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "pretty-ceramic",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### following the dictionaries, change the one character dipthongs to two charaters\n",
    "\n",
    "new_sy=[]\n",
    "for i in pr:\n",
    "    ii=[]\n",
    "    for j in i:\n",
    "        jj=[]\n",
    "        for k in j:\n",
    "            if k not in dpthn:\n",
    "                jj.append(k)\n",
    "            if k in dpthn:\n",
    "                jj.append(dpthn[k][0])\n",
    "                jj.append(dpthn[k][1])\n",
    "        ii.append(jj)\n",
    "    new_sy.append(ii)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "growing-integer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15174\n",
      "[[['AA1', 'R', 'D', 'V', 'AA2', 'R', 'K']], [['AE1', 'B', 'AH0', 'K', 'AH0', 'S']], [['AE1', 'B', 'AH0', 'K', 'AH0', 'S']], [['AE0', 'B', 'D', 'AH1', 'K', 'SH', 'AH0', 'N']], [['AE1', 'B', 'EH0', 'N', 'D']], [['AE1', 'B', 'EH0', 'N', 'D']], [['AH0', 'B', 'IH1', 'L', 'AH0', 'T', 'I', 'Y2']], [['AE0', 'B', 'N', 'AO1', 'R', 'M', 'AH0', 'L']], [['AE0', 'B', 'N', 'AO1', 'R', 'M', 'AH0', 'L'], ['EH1', 'N', 'D']], [['AE2', 'B', 'E', 'R0', 'IH1', 'JH', 'AH0', 'N', 'I', 'Y0']]]\n",
      "[[['Z', 'U', 'W2', 'L', 'AA1', 'JH', 'IH0', 'K', 'AH0', 'L']], [['Z', 'O', 'W0', 'AA1', 'L', 'AH0', 'JH', 'I', 'Y0']], [['Z', 'O', 'W0', 'AA1', 'L', 'AH0', 'JH', 'I', 'Y0']], [['Z', 'O', 'W0', 'AA1', 'L', 'AH0', 'JH', 'I', 'Y0']], [['Z', 'U', 'W1', 'M']], [['Z', 'U', 'W1', 'M', 'IH0', 'N', 'G']], [['Z', 'U', 'W0', 'K', 'I', 'Y1', 'N', 'I', 'Y0']], [['T', 'R', 'U', 'W1']], [['T', 'R', 'U', 'W1']], [['T', 'R', 'U', 'W1']]]\n"
     ]
    }
   ],
   "source": [
    "print(len(new_sy))\n",
    "# print(new_sy[:10])\n",
    "# print(new_sy[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "framed-laptop",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### use the phonological dictioanry, change the pronunciations to ether C, or V\n",
    "\n",
    "sylab2=[]\n",
    "for i in new_sy:\n",
    "    ii=[]\n",
    "    for j in i:\n",
    "        jj=[]\n",
    "        for k in j:\n",
    "            if k in ctl_patd:\n",
    "                jj.append(ctl_patd[k])\n",
    "        jjj=\"\".join(jj)\n",
    "        ii.append(jjj)\n",
    "    sylab2.append(ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "square-desperate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15174\n",
      "[['VCCCVCC'], ['VCVCVC'], ['VCVCVC'], ['VCCVCCVC'], ['VCVCC'], ['VCVCC'], ['VCVCVCVV'], ['VCCVCCVC'], ['VCCVCCVC', 'VCC'], ['VCVVVCVCVV']]\n",
      "[['CVVCVCVCVC'], ['CVVVCVCVV'], ['CVVVCVCVV'], ['CVVVCVCVV'], ['CVVC'], ['CVVCVCC'], ['CVVCVVCVV'], ['CCVV'], ['CCVV'], ['CCVV']]\n"
     ]
    }
   ],
   "source": [
    "print(len(sylab2))\n",
    "print(sylab2[:10])\n",
    "# print(sylab2[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "flexible-interference",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Since the katakana characters always represent two phoneme syllables(CV), so we recompose the CMU pronunciation like this \n",
    "#### In this step, the CV syllables' index are found. After found all CV, the left single C or V's index are also found\n",
    "\n",
    "sy_len=[]\n",
    "for i in sylab2:\n",
    "    ii=[]\n",
    "    for j in i:\n",
    "        jj=[]\n",
    "        k=re.finditer(\"CV\", j)\n",
    "        for h in k:\n",
    "            jj.append(h.span())\n",
    "        j1=j.replace(\"CV\",\"__\")\n",
    "        k1=re.finditer(\"V\", j1)\n",
    "        for h1 in k1:\n",
    "            jj.append(h1.span())\n",
    "        j2=j1.replace(\"V\",\"_\")\n",
    "        k2=re.finditer(\"C\", j2)\n",
    "        for h2 in k2:\n",
    "            jj.append(h2.span())\n",
    "            \n",
    "        ii.append(sorted(jj))\n",
    "    sy_len.append(ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "alpine-hundred",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15174\n",
      "[([['AA1', 'R', 'D', 'V', 'AA2', 'R', 'K']], [[(0, 1), (1, 2), (2, 3), (3, 5), (5, 6), (6, 7)]]), ([['AE1', 'B', 'AH0', 'K', 'AH0', 'S']], [[(0, 1), (1, 3), (3, 5), (5, 6)]]), ([['AE1', 'B', 'AH0', 'K', 'AH0', 'S']], [[(0, 1), (1, 3), (3, 5), (5, 6)]]), ([['AE0', 'B', 'D', 'AH1', 'K', 'SH', 'AH0', 'N']], [[(0, 1), (1, 2), (2, 4), (4, 5), (5, 7), (7, 8)]]), ([['AE1', 'B', 'EH0', 'N', 'D']], [[(0, 1), (1, 3), (3, 4), (4, 5)]]), ([['AE1', 'B', 'EH0', 'N', 'D']], [[(0, 1), (1, 3), (3, 4), (4, 5)]]), ([['AH0', 'B', 'IH1', 'L', 'AH0', 'T', 'I', 'Y2']], [[(0, 1), (1, 3), (3, 5), (5, 7), (7, 8)]]), ([['AE0', 'B', 'N', 'AO1', 'R', 'M', 'AH0', 'L']], [[(0, 1), (1, 2), (2, 4), (4, 5), (5, 7), (7, 8)]]), ([['AE0', 'B', 'N', 'AO1', 'R', 'M', 'AH0', 'L'], ['EH1', 'N', 'D']], [[(0, 1), (1, 2), (2, 4), (4, 5), (5, 7), (7, 8)], [(0, 1), (1, 2), (2, 3)]]), ([['AE2', 'B', 'E', 'R0', 'IH1', 'JH', 'AH0', 'N', 'I', 'Y0']], [[(0, 1), (1, 3), (3, 4), (4, 5), (5, 7), (7, 9), (9, 10)]])]\n"
     ]
    }
   ],
   "source": [
    "print(len(sy_len))\n",
    "sy_in=list(zip(new_sy, sy_len))\n",
    "print(sy_in[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "indoor-stewart",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### In this following step, recompose the pronunciation into CV patterns according to the index we got previously\n",
    "\n",
    "seg_cmu=[]\n",
    "for i in sy_in:\n",
    "    k=list(zip(i[0],i[1]))\n",
    "    ii=[]\n",
    "    for j in k:\n",
    "        j0=[]\n",
    "        for k1 in j[1]:\n",
    "            j0.append(j[0][k1[0]:k1[1]])\n",
    "        j1=[]\n",
    "        for u in j0:\n",
    "            q=\"_\".join(u)\n",
    "            j1.append(q)\n",
    "        ww=\"|\".join(j1)\n",
    "        ii.append(ww)\n",
    "    seg_cmu.append(ii)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "structural-prior",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'seg_cmu' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e1b3f2a547e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseg_cmu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseg_cmu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# print(seg_cmu[-10:])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'seg_cmu' is not defined"
     ]
    }
   ],
   "source": [
    "print(len((seg_cmu)))\n",
    "print(seg_cmu[:10])\n",
    "# print(seg_cmu[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "consistent-study",
   "metadata": {},
   "outputs": [],
   "source": [
    "procs3=[]\n",
    "for i in seg_cmu:\n",
    "    ii=\"|\".join(i)\n",
    "    procs3.append(ii)\n",
    "procs4=[]\n",
    "for i in procs3:\n",
    "    i0=[]\n",
    "    ii=i.split(\"|\")\n",
    "    for j in ii:\n",
    "        i0.append(j.split(\"_\"))\n",
    "    procs4.append(i0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "talented-seminar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15174\n",
      "[[['Z', 'U'], ['W2'], ['L', 'AA1'], ['JH', 'IH0'], ['K', 'AH0'], ['L']], [['Z', 'O'], ['W0'], ['AA1'], ['L', 'AH0'], ['JH', 'I'], ['Y0']], [['Z', 'O'], ['W0'], ['AA1'], ['L', 'AH0'], ['JH', 'I'], ['Y0']], [['Z', 'O'], ['W0'], ['AA1'], ['L', 'AH0'], ['JH', 'I'], ['Y0']], [['Z', 'U'], ['W1'], ['M']], [['Z', 'U'], ['W1'], ['M', 'IH0'], ['N'], ['G']], [['Z', 'U'], ['W0'], ['K', 'I'], ['Y1'], ['N', 'I'], ['Y0']], [['T'], ['R', 'U'], ['W1']], [['T'], ['R', 'U'], ['W1']], [['T'], ['R', 'U'], ['W1']]]\n"
     ]
    }
   ],
   "source": [
    "print(len((procs4)))\n",
    "print(procs4[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "progressive-series",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Now, deal with the katakana characters ---- attach the half size character to their preceding characters\n",
    "#### for every katakana words, if it contains the half size characters, the index of the charater will be found\n",
    "ids=[]\n",
    "for i in ka_w:\n",
    "    ii=[]\n",
    "    k=list(i)\n",
    "    for d,j in enumerate(k):\n",
    "        if j in hankaku:\n",
    "            ii.append((d))\n",
    "    ids.append(ii)\n",
    "bids=list(zip(ka_w, ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "prescription-acoustic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15174\n",
      "[('チター', []), ('ツィター', [1]), ('ゾーディアック', [3, 5]), ('ゾウディアック', [3, 5]), ('ゾディアック', [2, 4]), ('ゾンビ', []), ('ゾーン', []), ('ゾウン', []), ('ゾーニング', []), ('ゾゥァラジカル', [1, 2]), ('ゾウアラジカル', []), ('ズーオロジー', []), ('ゾゥアラジィ', [1, 5]), ('ゾウオロジー', []), ('ズーム', []), ('ズーミング', []), ('ズッキーニ', [1]), ('ツルー', []), ('トゥルー', [1]), ('トルー', [])]\n"
     ]
    }
   ],
   "source": [
    "print(len(bids))\n",
    "print(bids[-20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "raised-arkansas",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### for every katakana words that contains half-size character, the preceding charaters are found\n",
    "han_char=[]\n",
    "for i in bids:\n",
    "    ii=[]\n",
    "    k=list(i[0])\n",
    "    for j in i[1]:\n",
    "        m=k[j-1]+k[j]\n",
    "        ii.append(m)\n",
    "    l=list(zip(ii, i[1]))\n",
    "    res = list(map(list, l))\n",
    "    if len(res)<=1:\n",
    "        han_char.append(res)\n",
    "    if len(res)>1:\n",
    "        for o in range(1,len(res)):\n",
    "            if res[o][1]-res[o-1][1] ==1:\n",
    "                res[o-1][0]=res[o-1][0]+res[o][0][1]\n",
    "        han_char.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "ruled-daniel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15174\n",
      "[[], [['ツィ', 1]], [['ディ', 3], ['アッ', 5]], [['ディ', 3], ['アッ', 5]], [['ディ', 2], ['アッ', 4]], [], [], [], [], [['ゾゥァ', 1], ['ゥァ', 2]], [], [], [['ゾゥ', 1], ['ジィ', 5]], [], [], [], [['ズッ', 1]], [], [['トゥ', 1]], []]\n"
     ]
    }
   ],
   "source": [
    "print(len(han_char))\n",
    "print(han_char[-20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "civic-extraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### attach the half-size character to receding character\n",
    "larg_char=[]\n",
    "for i in han_char:\n",
    "    ii=[]\n",
    "    for j in i:\n",
    "        ii.append(j[0])\n",
    "#     print(ii)\n",
    "    iii=[]\n",
    "    for k in ii:\n",
    "        if k[0] not in hankaku:\n",
    "            iii.append(k)\n",
    "    larg_char.append(iii)\n",
    "\n",
    "lar_b=list(zip(ka_w,larg_char))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "adjacent-violence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15174\n",
      "[('チター', []), ('ツィター', ['ツィ']), ('ゾーディアック', ['ディ', 'アッ']), ('ゾウディアック', ['ディ', 'アッ']), ('ゾディアック', ['ディ', 'アッ']), ('ゾンビ', []), ('ゾーン', []), ('ゾウン', []), ('ゾーニング', []), ('ゾゥァラジカル', ['ゾゥァ']), ('ゾウアラジカル', []), ('ズーオロジー', []), ('ゾゥアラジィ', ['ゾゥ', 'ジィ']), ('ゾウオロジー', []), ('ズーム', []), ('ズーミング', []), ('ズッキーニ', ['ズッ']), ('ツルー', []), ('トゥルー', ['トゥ']), ('トルー', [])]\n"
     ]
    }
   ],
   "source": [
    "print(len(lar_b))\n",
    "print(lar_b[-20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "cooperative-cable",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Now, insert the attached characters back to the words\n",
    "\n",
    "larbb=[]\n",
    "for i in lar_b:\n",
    "    ii=[]\n",
    "    l=list(i)\n",
    "    for j in l[1]:\n",
    "        jj=l[0].replace(j, \"_\")\n",
    "        l[0]=jj\n",
    "    larbb.append(l)\n",
    "    \n",
    "    \n",
    "seg_kata=[]\n",
    "for i in larbb:\n",
    "    ii=[]\n",
    "    iii=[]\n",
    "    idd=re.finditer(\"_\", i[0])\n",
    "    for j in idd:\n",
    "        ii.append(j.span()[0])\n",
    "#     print(ii)\n",
    "    for j in i[0]:\n",
    "        if j != \"_\":\n",
    "            iii.append(j)\n",
    "    kd=list(zip(ii, i[1]))\n",
    "    for k in kd:\n",
    "        iii.insert(k[0],k[1])\n",
    "    seg_kata.append(iii)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "inner-stadium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15174\n",
      "[['ア', 'ー', 'ド', 'バ', 'ー', 'ク'], ['ア', 'バ', 'カ', 'ス'], ['ア', 'バ', 'ク', 'ス'], ['ア', 'ブ', 'ダ', 'ク', 'ショ', 'ン'], ['ア', 'ベ', 'ン', 'ド'], ['ア', 'ー', 'ベ', 'ン', 'ト'], ['ア', 'ビ', 'リ', 'ティ', 'ー'], ['ア', 'ブ', 'ノ', 'ー', 'マ', 'ル'], ['ア', 'ブ', 'ノ', 'ー', 'マ', 'ル', 'エ', 'ン', 'ド'], ['ア', 'ボ', 'リ', 'ジ', 'ニ']]\n",
      "[['ゾ', 'ウ', 'ア', 'ラ', 'ジ', 'カ', 'ル'], ['ズ', 'ー', 'オ', 'ロ', 'ジ', 'ー'], ['ゾゥ', 'ア', 'ラ', 'ジィ'], ['ゾ', 'ウ', 'オ', 'ロ', 'ジ', 'ー'], ['ズ', 'ー', 'ム'], ['ズ', 'ー', 'ミ', 'ン', 'グ'], ['ズッ', 'キ', 'ー', 'ニ'], ['ツ', 'ル', 'ー'], ['トゥ', 'ル', 'ー'], ['ト', 'ル', 'ー']]\n"
     ]
    }
   ],
   "source": [
    "print(len(seg_kata))\n",
    "print(seg_kata[:10])\n",
    "# print(seg_kata[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "accessory-factor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['Z', 'U'], ['W2'], ['L', 'AA1'], ['JH', 'IH0'], ['K', 'AH0'], ['L']], [['Z', 'O'], ['W0'], ['AA1'], ['L', 'AH0'], ['JH', 'I'], ['Y0']], [['Z', 'O'], ['W0'], ['AA1'], ['L', 'AH0'], ['JH', 'I'], ['Y0']], [['Z', 'O'], ['W0'], ['AA1'], ['L', 'AH0'], ['JH', 'I'], ['Y0']], [['Z', 'U'], ['W1'], ['M']], [['Z', 'U'], ['W1'], ['M', 'IH0'], ['N'], ['G']], [['Z', 'U'], ['W0'], ['K', 'I'], ['Y1'], ['N', 'I'], ['Y0']], [['T'], ['R', 'U'], ['W1']], [['T'], ['R', 'U'], ['W1']], [['T'], ['R', 'U'], ['W1']]]\n"
     ]
    }
   ],
   "source": [
    "print(procs4[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "going-yield",
   "metadata": {},
   "outputs": [],
   "source": [
    "# oo=[]\n",
    "# for i in procs4:\n",
    "#     for j in i:\n",
    "#         for k in j:\n",
    "#             if k not in ctl_lend:\n",
    "#                 oo.append(procs4.index(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "pointed-simulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(oo))\n",
    "# print(oo)\n",
    "# print(ka_w[6907])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "wicked-equation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### obtain the length of English pronunciation of each words\n",
    "cmu_len=[]\n",
    "for i in procs4:\n",
    "    ii=[]\n",
    "    for j in i:\n",
    "        jj=[]\n",
    "        for k in j:\n",
    "\n",
    "            jj.append(ctl_lend[k])\n",
    "        if len(jj) <=1:\n",
    "            ii.append(sum(jj))\n",
    "        if len(jj)>=2:\n",
    "            ii.append(sum(jj)-1)\n",
    "        \n",
    "\n",
    "    cmu_len.append(ii)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "strategic-wrestling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15174\n",
      "[[1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1], [1, 1, 1], [1, 1, 1]]\n"
     ]
    }
   ],
   "source": [
    "print(len(cmu_len))\n",
    "print(cmu_len[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "located-peripheral",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### This dictionary contains: katakana words seperated by characters; English pronunciation segmented; and the length of the rponunciation\n",
    "\n",
    "len_comp=list(zip(seg_kata, procs4, cmu_len))\n",
    "eq_len1=[] #the list of words that their katakana and English pronunciation are aligned in same length\n",
    "neq_len=[] #the list of words that their katakana and English pronunciation are not aligned in same length\n",
    "neq=[]\n",
    "for i in len_comp:\n",
    "    if len(i[0])==sum(i[2]):\n",
    "        eq_len1.append(i)\n",
    "    if len(i[0])!=sum(i[2]):\n",
    "        neq_len.append(i)\n",
    "        neq.append(len(i[0])-sum(i[2]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "catholic-killing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(eq_len1[690:700])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "satellite-track",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9667\n",
      "5507\n",
      "5507\n",
      "{1, 2, 3, -1, -4, -3, -2}\n"
     ]
    }
   ],
   "source": [
    "print(len(eq_len1))\n",
    "print(len(neq_len))\n",
    "print(len(neq))\n",
    "# print(set(neq))\n",
    "# print(neq_len[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "freelance-friday",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### save all the words whether aligned in the same length or not into a list\n",
    "\n",
    "\n",
    "jdatas=[]\n",
    "for i in len_comp:\n",
    "    ii=[]\n",
    "    ii.append(\" \".join(i[0]))\n",
    "    iii=[]\n",
    "    for j in i[1]:\n",
    "        jj=\"_\".join(j)\n",
    "        iii.append(jj)\n",
    "    ii.append(\" \".join(iii))\n",
    "    jdatas.append(ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "interesting-amplifier",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15174\n",
      "[['ア ー ド バ ー ク', 'AA1 R D V_AA2 R K'], ['ア バ カ ス', 'AE1 B_AH0 K_AH0 S'], ['ア バ ク ス', 'AE1 B_AH0 K_AH0 S'], ['ア ブ ダ ク ショ ン', 'AE0 B D_AH1 K SH_AH0 N'], ['ア ベ ン ド', 'AE1 B_EH0 N D'], ['ア ー ベ ン ト', 'AE1 B_EH0 N D'], ['ア ビ リ ティ ー', 'AH0 B_IH1 L_AH0 T_I Y2'], ['ア ブ ノ ー マ ル', 'AE0 B N_AO1 R M_AH0 L'], ['ア ブ ノ ー マ ル エ ン ド', 'AE0 B N_AO1 R M_AH0 L EH1 N D'], ['ア ボ リ ジ ニ', 'AE2 B_E R0 IH1 JH_AH0 N_I Y0']]\n"
     ]
    }
   ],
   "source": [
    "print(len(jdatas))\n",
    "print(jdatas[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "automotive-think",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "with open(\"JMdict_aligned.csv\", \"w\") as jf:\n",
    "    csvwriter = csv.writer(jf, delimiter='\\t')\n",
    "    csvwriter.writerows(jdatas)\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "cathedral-gothic",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# exmp=[]\n",
    "# # exmpp=[]\n",
    "# for i in neq_len:\n",
    "#     if len(i[0])-len(i[1])== 3:\n",
    "# #         print(i)\n",
    "#         exmp.append(i)\n",
    "# print(len(exmp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "touched-heaven",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2589\n",
      "1916\n"
     ]
    }
   ],
   "source": [
    "# exmp=[]\n",
    "# exmpp=[]\n",
    "# for i in neq_len:\n",
    "#     if len(i[0])-len(i[1])== -1:\n",
    "#         exmp.append(i)\n",
    "#     if len(i[0])-len(i[1])== 1:\n",
    "#         exmpp.append(i)\n",
    "# print(len(exmp))\n",
    "# print(len(exmpp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "residential-longer",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125\n"
     ]
    }
   ],
   "source": [
    "# ex2=[]\n",
    "\n",
    "# for i in exmp:\n",
    "#     ii=[]\n",
    "#     if ['R0'] in i[1] and i[1].index(['R0'])==len(i[1])-1:\n",
    "#         ex2.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "grave-palmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ex1=[]\n",
    "# exx1=[]\n",
    "\n",
    "# for i in exmp:\n",
    "#     ii=[]\n",
    "#     if ['R0'] in i[1] and i[1].index(['R0'])!=len(i[1])-1:\n",
    "#         idd=i[1].index(['R0'])\n",
    "#         if len(i[1][idd+1]) >1:\n",
    "#             exx1.append(i)\n",
    "#         if len(i[1][idd+1]) <=1:\n",
    "#             ex1.append(i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "impaired-pressure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "541\n"
     ]
    }
   ],
   "source": [
    "# sum0=exx1+exxx1\n",
    "# print(len(sum0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "brave-contribution",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "425\n",
      "[(['ア', 'キュ', 'ー', 'ム', 'レ', 'ー', 'タ'], [['AH0'], ['KY', 'U'], ['W1'], ['MY', 'AH0'], ['L', 'E'], ['Y2'], ['T', 'E', 'R0']], [1, 1, 1, 1, 1, 1, 1, 1]), (['ア', 'キュ', 'ム', 'レ', 'ー', 'タ', 'ー'], [['AH0'], ['KY', 'U'], ['W1'], ['MY', 'AH0'], ['L', 'E'], ['Y2'], ['T', 'E'], ['R0']], [1, 1, 1, 1, 1, 1, 1, 1]), (['ア', 'ク', 'ワ', 'イ', 'ア'], [['AH0'], ['K'], ['W', 'A'], ['Y1'], ['E', 'R0']], [1, 1, 1, 1, 1, 1]), (['ア', 'ク', 'ワ', 'イ', 'ヤ'], [['AH0'], ['K'], ['W', 'A'], ['Y1'], ['E', 'R0']], [1, 1, 1, 1, 1, 1]), (['ア', 'ク', 'チ', 'ベ', 'ー', 'タ'], [['AE1'], ['K'], ['T', 'AH0'], ['V', 'E'], ['Y2'], ['T', 'E', 'R0']], [1, 1, 1, 1, 1, 1, 1]), (['ア', 'ク', 'ティ', 'ベ', 'ー', 'タ'], [['AE1'], ['K'], ['T', 'AH0'], ['V', 'E'], ['Y2'], ['T', 'E', 'R0']], [1, 1, 1, 1, 1, 1, 1]), (['ア', 'ク', 'ティ', 'ブ', 'タ', 'ー', 'ミ', 'ネ', 'ー', 'タ'], [['AE1'], ['K'], ['T', 'IH0'], ['V'], ['T', 'E'], ['R1'], ['M', 'IH0'], ['N', 'E'], ['Y2'], ['T', 'E', 'R0']], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), (['ア', 'ク', 'タ'], [['AE1'], ['K'], ['T', 'E', 'R0']], [1, 1, 1, 1]), (['ア', 'ク', 'チュ', 'エ', 'ー', 'タ', 'ー'], [['AE1'], ['K'], ['TY', 'U'], ['W0'], ['E'], ['Y2'], ['T', 'E'], ['R0']], [1, 1, 1, 1, 1, 1, 1, 1]), (['ア', 'ダ', 'プ', 'タ'], [['AH0'], ['D', 'AE1'], ['P'], ['T', 'E', 'R0']], [1, 1, 1, 1, 1])]\n"
     ]
    }
   ],
   "source": [
    "# print(len(ex2))\n",
    "# exx2=[]\n",
    "# for i in ex2:\n",
    "#     if i[0][-1] == 'ー':\n",
    "#         exx2.append(i)\n",
    "#     if i[0][-1] != 'ー':\n",
    "#         i[1][-2]=i[1][-2]+i[1][-1]\n",
    "#         i[1].remove(i[1][-1])\n",
    "#         exx2.append(i)\n",
    "# print(exx2[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "compliant-mattress",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "966\n",
      "[['ア', 'ド', 'バ', 'タ', 'イ', 'ジ', 'ン', 'グ'], ['ア', 'フ', 'タ', 'ヌ', 'ー', 'ン'], ['ア', 'ー', 'フ', 'タ', 'ワ', 'ー', 'ズ'], ['オ', 'ル', 'タ', 'ネ', 'ー', 'タ', 'ー'], ['ア', 'ン', 'パ', 'サ', 'ン', 'ド'], ['ア', 'ナ', 'キ', 'ス', 'ト'], ['ア', 'ン', 'カ', 'ー', 'マ', 'ン'], ['ア', 'ン', 'サ', 'ホ', 'ン'], ['ア', 'パ', 'ー', 'チャ'], ['バ', 'ミュ', 'ー', 'ダ']]\n"
     ]
    }
   ],
   "source": [
    "# sum1=sum0+exx2\n",
    "# print(len(sum1))\n",
    "# sum1w=[]\n",
    "# for i in sum1:\n",
    "#     sum1w.append(i[0])\n",
    "# print(sum1w[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "objective-apparel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1942\n"
     ]
    }
   ],
   "source": [
    "# exx3=[]\n",
    "# for i in exmp:\n",
    "#     if i[0] not in sum1w:\n",
    "#         exx3.append(i)\n",
    "# print(len(exx3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "arbitrary-creature",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exmp1=[]\n",
    "# for i in exmpp:\n",
    "#     if 'ー' not in i[0]:\n",
    "#         exmp1.append(i)\n",
    "#     ii=[]\n",
    "#     if 'ー' in i[0]:\n",
    "#         idd=i[0].index('ー')\n",
    "#         j=i[0][idd-1]+'ー'\n",
    "#         k=i[0][:idd-1]\n",
    "#         k.append(j)\n",
    "#         kk=k+i[0][idd+1:]\n",
    "# #         kk=k.append(i[0][idd+1:])\n",
    "#         ii.append(kk)\n",
    "#         ii.append(i[1])\n",
    "#         exmp1.append(ii)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "steady-scheme",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1916\n",
      "2882\n"
     ]
    }
   ],
   "source": [
    "# print(len(exmp1))\n",
    "# count=0\n",
    "# for i in exmp1:\n",
    "#     if len(i[0])==len(i[1]):\n",
    "#         count+=1\n",
    "# # print(count)\n",
    "# sum2=sum1+exmp1\n",
    "# print(len(sum2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "romance-aruba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12456\n"
     ]
    }
   ],
   "source": [
    "# sum3=sum2+eq_len1\n",
    "# print(len(sum3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "promotional-correction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# jdatas=[]\n",
    "# for i in sum3:\n",
    "#     ii=[]\n",
    "#     ii.append(\"=\".join(i[0]))\n",
    "#     iii=[]\n",
    "#     for j in i[1]:\n",
    "#         jj=\"_\".join(j)\n",
    "#         iii.append(jj)\n",
    "#     ii.append(\"=\".join(iii))\n",
    "#     jdatas.append(ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "textile-bullet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eqls=[]\n",
    "# for i in eq_len1:\n",
    "#     ii=[]\n",
    "#     ii.append(\"|\".join(i[0]))\n",
    "#     iii=[]\n",
    "#     for j in i[1]:\n",
    "#         jj=\"_\".join(j)\n",
    "#         iii.append(jj)\n",
    "#     ii.append(\"|\".join(iii))\n",
    "# #     ii.append(i[2])\n",
    "# #     ii.append(len(i[0])-sum(i[2]))\n",
    "#     eqls.append(ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "interested-measurement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# neqls=[]\n",
    "# for i in neq_len:\n",
    "#     ii=[]\n",
    "#     ii.append(\"|\".join(i[0]))\n",
    "#     iii=[]\n",
    "#     for j in i[1]:\n",
    "#         jj=\"_\".join(j)\n",
    "#         iii.append(jj)\n",
    "#     ii.append(\"|\".join(iii))\n",
    "# #     ii.append(i[2])\n",
    "#     ii.append(len(i[0])-sum(i[2]))\n",
    "#     neqls.append(ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "early-provision",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
