{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "controlling-excuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### import library calculate the WER\n",
    "\n",
    "from jiwer import wer\n",
    "\n",
    "ground_truth = \"hello world\"\n",
    "hypothesis = \"hello duck\"\n",
    "\n",
    "error = wer(ground_truth, hypothesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "informal-asbestos",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "incorporate-jordan",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### open result file\n",
    "lines=[]\n",
    "with open(\"KaToLetter_checkpoint_best.txt\", \"r\", encoding=\"utf-8\") as klf:\n",
    "    for i in klf:\n",
    "        l=i.rstrip().split(\"\\t\")\n",
    "        lines.append(l)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "mature-fashion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13351\n",
      "[['S-436', 'ス ト ー リ ー'], ['T-436', 's t o r y'], ['H-436', '-0.12009063363075256', 's t o r y'], ['D-436', '-0.12009063363075256', 's t o r y'], ['P-436', '-0.1099 -0.0858 -0.1454 -0.1039 -0.1772 -0.0983'], ['S-601', 'メ ダ リ ス ト']]\n"
     ]
    }
   ],
   "source": [
    "print(len(lines))\n",
    "print(lines[:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "minus-ethernet",
   "metadata": {},
   "outputs": [],
   "source": [
    "line_sub1=lines[::5]\n",
    "line_sub2=lines[1::5]\n",
    "line_sub3=lines[2::5]\n",
    "results=list(zip(line_sub1[:-1], line_sub2, line_sub3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "preceding-equity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2670\n",
      "(['S-2290', 'ラ イ ト ニ ン グ ト ー ク'], ['T-2290', 'l i g h t n i n g t a l k'], ['H-2290', '-0.08378349989652634', 'l i g h t n i n g t a l k'])\n"
     ]
    }
   ],
   "source": [
    "print(len(results))\n",
    "print(results[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "resident-botswana",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_word=[]# the source language\n",
    "ans=[]# the target language\n",
    "hy_w=[]# the predicted language\n",
    "score=[]# the WER language\n",
    "for i in results:\n",
    "    \n",
    "    s_word.append(i[0][1])\n",
    "    ans.append(i[1][1])\n",
    "    hy_w.append(i[2][2])\n",
    "    j=wer(i[1][1], i[2][2])\n",
    "    score.append(round(j, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "automated-elizabeth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2670\n",
      "['ス ト ー リ ー', 'メ ダ リ ス ト', 'ア セ ン ブ リ', 'チェッ ク ア ウ ト', 'メ ディ ケ イ ド']\n",
      "2670\n",
      "['s t o r y', 'm e d a l i s t', 'a s s e m b l y', 'c h e c k o u t', 'm e d i c a i d']\n",
      "2670\n",
      "['s t o r y', 'm e d a l i s t', 'a s s e m b l y', 'c h e c k o u t', 'm e d i c a d e']\n",
      "2670\n",
      "[0.0, 0.0, 0.0, 0.0, 0.25]\n"
     ]
    }
   ],
   "source": [
    "print(len(s_word))\n",
    "print(s_word[:5])\n",
    "print(len(ans))\n",
    "print(ans[:5])\n",
    "print(len(hy_w))\n",
    "print(hy_w[:5])\n",
    "print(len(score))\n",
    "print(score[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "retained-ferry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2668\n",
      "2668\n"
     ]
    }
   ],
   "source": [
    "s_t=list(zip(s_word, ans))#source word and target word\n",
    "predicts=dict(zip(s_t, score))#(source word and target word, WER score)\n",
    "pred_words=dict(zip(s_t, hy_w))#(source word and target word, predicted word)\n",
    "print(len(predicts))\n",
    "print(len(pred_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "quick-tragedy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1638\n"
     ]
    }
   ],
   "source": [
    "##### Number of words with ) WER\n",
    "\n",
    "pred=list(zip(s_t, score))\n",
    "cor_ph=[]\n",
    "for i in pred:\n",
    "    if i[1] == 0.0:\n",
    "        cor_ph.append(i[0])\n",
    "print(len(cor_ph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "wicked-composer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Repeat(x):\n",
    "    _size = len(x)\n",
    "    repeated = []\n",
    "    for i in range(_size):\n",
    "        k = i + 1\n",
    "        for j in range(k, _size):\n",
    "            if x[i] == x[j] and x[i] not in repeated:\n",
    "                repeated.append(x[i])\n",
    "    return repeated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "another-conjunction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "[('バ ー ジ ン', 'v i r g i n'), ('ラ ブ コ メ ディ ー', 'l o v e c o m e d y')]\n"
     ]
    }
   ],
   "source": [
    "#### The test data contains some duplicates\n",
    "dups=Repeat(s_t)\n",
    "print(len(dups))\n",
    "# print(dups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "charming-morrison",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1638\n",
      "138\n",
      "344\n",
      "214\n",
      "144\n",
      "192\n"
     ]
    }
   ],
   "source": [
    "#### NOW, calculate the portion of words with difference correctness\n",
    "corrects=[] # number of words that are 100% correct\n",
    "nines=[] # number of words that are 90% correct(90% CA)\n",
    "eights=[] # number of words that are 80% correct(80% CA)\n",
    "sevens=[] # number of words that are 70% correct(70% CA)\n",
    "sixs=[] # number of words that are 60% correct(60% CA)\n",
    "rests=[]\n",
    "for i in score:\n",
    "    \n",
    "    if i == 0.0:\n",
    "        corrects.append(i)\n",
    "    if i > 0.0 and i <=0.1:\n",
    "        nines.append(i)\n",
    "    if i > 0.1 and i <=0.2:\n",
    "        eights.append(i)\n",
    "    if i > 0.2 and i <=0.3:\n",
    "        sevens.append(i)\n",
    "    if i > 0.3 and i <=0.4:\n",
    "        sixs.append(i)\n",
    "    if i > 0.4:\n",
    "        rests.append(i)\n",
    "\n",
    "print(len(corrects))\n",
    "print(len(nines))\n",
    "print(len(eights))\n",
    "print(len(sevens))\n",
    "print(len(sixs))\n",
    "print(len(rests))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "competent-symphony",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11\n"
     ]
    }
   ],
   "source": [
    "##### this is the average Character level error rate on the test data\n",
    "\n",
    "ave_ca= sum(score)/len(score)\n",
    "print(round(ave_ca, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "abroad-insulin",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### This part is the evaluation of the other direction transliteration \n",
    "###### the code is as same as above\n",
    "\n",
    "lines1=[]\n",
    "with open(\"LetToKata_checkpoint_best.txt\", \"r\", encoding=\"utf-8\") as lkf:\n",
    "    for i in lkf:\n",
    "        l=i.rstrip().split(\"\\t\")\n",
    "        lines1.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "textile-briefs",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13351\n",
      "[['S-2172', 'e x c u s e m e'], ['T-2172', 'エ ク ス キュ ー ズ ミ ー'], ['H-2172', '-0.1687702089548111', 'エ ク ス キュ ー ズ ム'], ['D-2172', '-0.1687702089548111', 'エ ク ス キュ ー ズ ム'], ['P-2172', '-0.0802 -0.3377 -0.1122 -0.0750 -0.1134 -0.0977 -0.4013 -0.1326'], ['S-2601', 'o p e n d a t a']]\n"
     ]
    }
   ],
   "source": [
    "print(len(lines1))\n",
    "# print(lines1[:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "decent-albert",
   "metadata": {},
   "outputs": [],
   "source": [
    "line1_sub1=lines1[::5]\n",
    "line1_sub2=lines1[1::5]\n",
    "line1_sub3=lines1[2::5]\n",
    "results1=list(zip(line1_sub1[:-1], line1_sub2, line1_sub3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "seven-index",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2670\n",
      "(['S-2504', 's u p p l y c h a i n m a n a g e m e n t'], ['T-2504', 'サ プ ラ イ チェ ー ン マ ネ ジ メ ン ト'], ['H-2504', '-0.09644363820552826', 'サ プ ラ イ チェ ー ン マ ネ ー ジ メ ン ト'])\n"
     ]
    }
   ],
   "source": [
    "print(len(results1))\n",
    "print(results1[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "adopted-certificate",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_word1=[]\n",
    "ans1=[]\n",
    "hy_w1=[]\n",
    "score1=[]\n",
    "for i in results1:\n",
    "    \n",
    "    s_word1.append(i[0][1])\n",
    "    ans1.append(i[1][1])\n",
    "    hy_w1.append(i[2][2])\n",
    "    j=wer(i[1][1], i[2][2])\n",
    "    score1.append(round(j, 2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "anonymous-position",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2670\n",
      "['e x c u s e m e', 'o p e n d a t a', 'b i o m u s i c', 'a u r e v o i r', 's o u n d b o x']\n",
      "2670\n",
      "['エ ク ス キュ ー ズ ミ ー', 'オ ー プ ン デ ー タ', 'バ イ オ ミュ ー ジッ ク', 'オ ー ル ヴォ ワ ー ル', 'サ ウ ン ド ボッ ク ス']\n",
      "2670\n",
      "['エ ク ス キュ ー ズ ム', 'オ ー プ ン デ ー タ', 'バ イ オ ミュ ー ジッ ク', 'オ ー ル ボ ワ ー ル', 'サ ウ ン ド ボッ ク ス']\n",
      "2670\n",
      "[0.25, 0.0, 0.0, 0.14, 0.0]\n"
     ]
    }
   ],
   "source": [
    "print(len(s_word1))\n",
    "print(s_word1[:5])\n",
    "print(len(ans1))\n",
    "print(ans1[:5])\n",
    "print(len(hy_w1))\n",
    "print(hy_w1[:5])\n",
    "print(len(score1))\n",
    "print(score1[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "greater-cancer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2668\n",
      "2670\n"
     ]
    }
   ],
   "source": [
    "s_t1=list(zip(s_word1, ans1))\n",
    "predicts1=dict(zip(s_t1, score1))\n",
    "print(len(predicts1))\n",
    "pred_en=list(zip(s_t1, hy_w1))\n",
    "print(len(pred_en))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "innocent-arabic",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1=list(zip(s_t1, score1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "recognized-greeting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "dups1=Repeat(s_t1)\n",
    "print(len(dups1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "random-theory",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0, 0.0], [0.33, 0.33]]\n"
     ]
    }
   ],
   "source": [
    "dup_in1=[]\n",
    "for i in dups1:\n",
    "    ii=[]\n",
    "    for j in pred1:\n",
    "        if i == j[0]:\n",
    "            ii.append(j[1])\n",
    "    dup_in1.append(ii)\n",
    "print(dup_in1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "sunrise-corrections",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1511\n",
      "45\n",
      "407\n",
      "219\n",
      "224\n",
      "264\n"
     ]
    }
   ],
   "source": [
    "\n",
    "corrects1=[]\n",
    "nines1=[]\n",
    "eights1=[]\n",
    "sevens1=[]\n",
    "sixs1=[]\n",
    "rests1=[]\n",
    "for i in score1:\n",
    "    \n",
    "    if i == 0.0:\n",
    "        corrects1.append(i)\n",
    "    if i > 0.0 and i <=0.1:\n",
    "        nines1.append(i)\n",
    "    if i > 0.1 and i <=0.2:\n",
    "        eights1.append(i)\n",
    "    if i > 0.2 and i <=0.3:\n",
    "        sevens1.append(i)\n",
    "    if i > 0.3 and i <=0.4:\n",
    "        sixs1.append(i)\n",
    "    if i > 0.4:\n",
    "        rests1.append(i)\n",
    "\n",
    "print(len(corrects1))\n",
    "print(len(nines1))\n",
    "print(len(eights1))\n",
    "print(len(sevens1))\n",
    "print(len(sixs1))\n",
    "print(len(rests1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "improving-translator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14\n"
     ]
    }
   ],
   "source": [
    "ave_ca1= sum(score1)/len(score1)\n",
    "print(round(ave_ca1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "swedish-particular",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### This part is the evaluation of Word Level Accuracy\n",
    "###### open the test files\n",
    "\n",
    "cmutest=[]\n",
    "with open(\"test.cmu\", \"r\", encoding=\"utf-8\") as cf:\n",
    "    for i in cf:\n",
    "        l=i.rstrip()\n",
    "        cmutest.append(l)\n",
    "        \n",
    "kcmutest=[]\n",
    "with open(\"test.kcmu\", \"r\", encoding=\"utf-8\") as kcf:\n",
    "    for i in kcf:\n",
    "        l=i.rstrip()\n",
    "        kcmutest.append(l)\n",
    "        \n",
    "katatest=[]\n",
    "with open(\"test.kata\", \"r\", encoding=\"utf-8\") as kaf:\n",
    "    for i in kaf:\n",
    "        l=i.rstrip()\n",
    "        katatest.append(l)\n",
    "        \n",
    "engtest=[]\n",
    "with open(\"test.eng\", \"r\", encoding=\"utf-8\") as enf:\n",
    "    for i in enf:\n",
    "        l=i.rstrip()\n",
    "        engtest.append(l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "worse-protein",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2670\n",
      "2670\n",
      "['AY M AE S K', 'IH S T AE B L IH SH M AH N T', 'P AO R S AH L AH N', 'N AA CH', 'HH OW S T IH NG S ER V ER', 'K AA N D ER', 'K AH S T AH M D AY AH L AO G B AA K S', 'CH AY N AH R IH S K', 'S K AO R P IY AH N', 'D EY V AH S K AH P']\n",
      "['A Y MAE S K', 'IH S TAE B LIH SH MAH N T', 'PAO R SAH LAH N', 'NAA CH', 'HHO W S TIH N G SE R VE R', 'KAA N DE R', 'KAH S TAH M DA Y AH LAO G BAA K S', 'CHA Y NAH RIH S K', 'S KAO R PI Y AH N', 'DE Y VAH S KAH P']\n",
      "2670\n",
      "['ア イ マ ス ク', 'イ ス タ ブ リッ シュ メ ン ト', 'ポ ー セ レ ン', 'ノッ チ', 'ホ ス ティ ン グ サ ー バ', 'コ ン ド ル', 'カ ス タ ム ダ イ ア ロ グ ボッ ク ス', 'チャ イ ナ リ ス ク', 'ス コ ー ピ オ ン', 'デ ビ ス カッ プ']\n",
      "2670\n",
      "['e y e m a s k', 'e s t a b l i s h m e n t', 'p o r c e l a i n', 'n o t c h', 'h o s t i n g s e r v e r', 'c o n d o r', 'c u s t o m d i a l o g b o x', 'c h i n a r i s k', 's c o r p i o n', 'd a v i s c u p']\n"
     ]
    }
   ],
   "source": [
    "print(len(cmutest))\n",
    "print(len(kcmutest))\n",
    "print(cmutest[:10])\n",
    "print(kcmutest[:10])\n",
    "print(len(katatest))\n",
    "print(katatest[:10])\n",
    "print(len(engtest))\n",
    "print(engtest[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "otherwise-prince",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### calculate the translation between english words and their CMU pronunciation first\n",
    "\n",
    "ec=list(zip(engtest, cmutest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dental-protocol",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2670\n",
      "[('e y e m a s k', 'AY M AE S K'), ('e s t a b l i s h m e n t', 'IH S T AE B L IH SH M AH N T'), ('p o r c e l a i n', 'P AO R S AH L AH N'), ('n o t c h', 'N AA CH'), ('h o s t i n g s e r v e r', 'HH OW S T IH NG S ER V ER'), ('c o n d o r', 'K AA N D ER'), ('c u s t o m d i a l o g b o x', 'K AH S T AH M D AY AH L AO G B AA K S'), ('c h i n a r i s k', 'CH AY N AH R IH S K'), ('s c o r p i o n', 'S K AO R P IY AH N'), ('d a v i s c u p', 'D EY V AH S K AH P')]\n"
     ]
    }
   ],
   "source": [
    "print(len(ec))\n",
    "# print(ec[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "historic-index",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('y 2 k', 'W AY T UW K EY')\n",
      "2669\n"
     ]
    }
   ],
   "source": [
    "#### find out which words contains the <unk> tag\n",
    "\n",
    "tt=[]\n",
    "for i in ec:#(The answers of english word and their pronunciation)\n",
    "    if i in s_t:#(The source word(katakana) and the target(pronunciation))\n",
    "        tt.append(i)\n",
    "    if i not in s_t:\n",
    "        print(i)\n",
    "print(len(tt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "champion-valley",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2670\n"
     ]
    }
   ],
   "source": [
    "#### find the WER score of words contain <unk>\n",
    "rescores=[]\n",
    "for i in ec:\n",
    "    if i==('y 2 k', 'W AY T UW K EY'):\n",
    "        rescores.append(predicts[('y <unk> k', 'W AY T UW K EY')])\n",
    "    if i in predicts:\n",
    "        rescores.append(predicts[i])\n",
    "print(len(rescores))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "taken-radar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2670\n"
     ]
    }
   ],
   "source": [
    "##### find the predictions of words contain <unk>\n",
    "\n",
    "re_predwords=[]\n",
    "for i in ec:\n",
    "    if i==('y 2 k', 'W AY T UW K EY'):\n",
    "        re_predwords.append(pred_words[('y <unk> k', 'W AY T UW K EY')])\n",
    "#     if i==('スェッ ト', 'S WEH T'):\n",
    "#         re_predwords.append(pred_words[('<unk> ト', 'S WEH T')])\n",
    "#     if i==('ラッ キィ', 'LAH KI Y'):\n",
    "#         re_predwords.append(pred_words[('ラッ <unk>', 'LAH KI Y')])\n",
    "#     if i==('ベ イ ジ ア ン', 'BE Y ZHIH N'):\n",
    "#         re_predwords.append(pred_words[('ベ イ ジ ア ン', 'BE Y <<unk>> N')])\n",
    "#     if i==('ヴェ ル ヴェッ ッ ト', 'VEH L VAH T'):\n",
    "#         re_predwords.append(pred_words[('ヴェ ル <unk> ッ ト', 'VEH L VAH T')])\n",
    "#     if i==('コ ー ト ヤ ー ド', 'KAO R TYAA R D'):\n",
    "#         re_predwords.append(pred_words[('コ ー ト ヤ ー ド', 'KAO R <<unk>> R D')])   \n",
    "    if i in pred_words:\n",
    "        re_predwords.append(pred_words[i])\n",
    "print(len(re_predwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ordinary-canberra",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2670\n",
      "[(('e y e m a s k', 'AY M AE S K'), 0.0), (('e s t a b l i s h m e n t', 'IH S T AE B L IH SH M AH N T'), 0.0), (('p o r c e l a i n', 'P AO R S AH L AH N'), 0.0), (('n o t c h', 'N AA CH'), 0.0), (('h o s t i n g s e r v e r', 'HH OW S T IH NG S ER V ER'), 0.0), (('c o n d o r', 'K AA N D ER'), 0.0), (('c u s t o m d i a l o g b o x', 'K AH S T AH M D AY AH L AO G B AA K S'), 0.06), (('c h i n a r i s k', 'CH AY N AH R IH S K'), 0.0), (('s c o r p i o n', 'S K AO R P IY AH N'), 0.0), (('d a v i s c u p', 'D EY V AH S K AH P'), 0.25)]\n"
     ]
    }
   ],
   "source": [
    "Ktest_score=list(zip(ec, rescores))#(The answer pair of English words and their pronunciation, their WER score)\n",
    "print(len(Ktest_score))\n",
    "print(Ktest_score[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "passive-encoding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2670\n",
      "[('A Y MAE S K', 'ア イ マ ス ク'), ('IH S TAE B LIH SH MAH N T', 'イ ス タ ブ リッ シュ メ ン ト'), ('PAO R SAH LAH N', 'ポ ー セ レ ン'), ('NAA CH', 'ノッ チ'), ('HHO W S TIH N G SE R VE R', 'ホ ス ティ ン グ サ ー バ'), ('KAA N DE R', 'コ ン ド ル'), ('KAH S TAH M DA Y AH LAO G BAA K S', 'カ ス タ ム ダ イ ア ロ グ ボッ ク ス'), ('CHA Y NAH RIH S K', 'チャ イ ナ リ ス ク'), ('S KAO R PI Y AH N', 'ス コ ー ピ オ ン'), ('DE Y VAH S KAH P', 'デ ビ ス カッ プ')]\n"
     ]
    }
   ],
   "source": [
    "####### Now calculate the tranliteration of aligned pronunciation and katakana words\n",
    "mk=list(zip(kcmutest, katatest))\n",
    "print(len(mk))\n",
    "print(mk[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "blank-prototype",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('AA R BIH T RAA ZHE R', 'ア ー ビ ト レィ ジャ ー')\n",
      "('S WEH T', 'スェッ ト')\n",
      "('LAH KI Y', 'ラッ キィ')\n",
      "('BE Y ZHIH N', 'ベ イ ジ ア ン')\n",
      "('VEH L VAH T', 'ヴェ ル ヴェッ ッ ト')\n",
      "('KAO R TYAA R D', 'コ ー ト ヤ ー ド')\n",
      "2664\n"
     ]
    }
   ],
   "source": [
    "ttt= []\n",
    "for i in mk:\n",
    "    if i in s_t1:\n",
    "        ttt.append(i)\n",
    "    if i not in s_t1:\n",
    "        print(i)\n",
    "print(len(ttt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "strong-carpet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2670\n"
     ]
    }
   ],
   "source": [
    "rescores1=[]\n",
    "for i in mk:\n",
    "    if i == ('KAO R TYAA R D', 'コ ー ト ヤ ー ド'):\n",
    "        rescores1.append(predicts1[('KAO R <unk> R D', 'コ ー ト ヤ ー ド')])\n",
    "    if i == ('VEH L VAH T', 'ヴェ ル ヴェッ ッ ト'):\n",
    "        rescores1.append(predicts1[('VEH L VAH T', 'ヴェ ル <<unk>> ッ ト')])\n",
    "    if i == ('BE Y ZHIH N', 'ベ イ ジ ア ン'):\n",
    "        rescores1.append(predicts1[('BE Y <unk> N', 'ベ イ ジ ア ン')])\n",
    "    if i == ('LAH KI Y', 'ラッ キィ'):\n",
    "        rescores1.append(predicts1[('LAH KI Y', 'ラッ <<unk>>')])\n",
    "    if i == ('S WEH T', 'スェッ ト'):\n",
    "        rescores1.append(predicts1[('S WEH T', '<<unk>> ト')])\n",
    "    if i == ('AA R BIH T RAA ZHE R', 'ア ー ビ ト レィ ジャ ー'):\n",
    "        rescores1.append(predicts1[('AA R BIH T RAA ZHE R', 'ア ー ビ ト <<unk>> ジャ ー')])\n",
    "    if i in predicts1:\n",
    "        rescores1.append(predicts1[i])\n",
    "print(len(rescores1))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "smart-granny",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2670\n"
     ]
    }
   ],
   "source": [
    "Etest_score=list(zip(mk, rescores1))\n",
    "print(len(Etest_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "brutal-right",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('A Y MAE S K', 'ア イ マ ス ク'), 0.0), (('IH S TAE B LIH SH MAH N T', 'イ ス タ ブ リッ シュ メ ン ト'), 0.0), (('PAO R SAH LAH N', 'ポ ー セ レ ン'), 0.2), (('NAA CH', 'ノッ チ'), 0.0), (('HHO W S TIH N G SE R VE R', 'ホ ス ティ ン グ サ ー バ'), 0.12), (('KAA N DE R', 'コ ン ド ル'), 0.5), (('KAH S TAH M DA Y AH LAO G BAA K S', 'カ ス タ ム ダ イ ア ロ グ ボッ ク ス'), 0.0), (('CHA Y NAH RIH S K', 'チャ イ ナ リ ス ク'), 0.0), (('S KAO R PI Y AH N', 'ス コ ー ピ オ ン'), 0.17), (('DE Y VAH S KAH P', 'デ ビ ス カッ プ'), 0.2)]\n"
     ]
    }
   ],
   "source": [
    "print(Etest_score[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "pursuant-baking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('e y e m a s k', 'AY M AE S K'), 0.0), (('e s t a b l i s h m e n t', 'IH S T AE B L IH SH M AH N T'), 0.0), (('p o r c e l a i n', 'P AO R S AH L AH N'), 0.0), (('n o t c h', 'N AA CH'), 0.0), (('h o s t i n g s e r v e r', 'HH OW S T IH NG S ER V ER'), 0.0), (('c o n d o r', 'K AA N D ER'), 0.0), (('c u s t o m d i a l o g b o x', 'K AH S T AH M D AY AH L AO G B AA K S'), 0.06), (('c h i n a r i s k', 'CH AY N AH R IH S K'), 0.0), (('s c o r p i o n', 'S K AO R P IY AH N'), 0.0), (('d a v i s c u p', 'D EY V AH S K AH P'), 0.25)]\n"
     ]
    }
   ],
   "source": [
    "print(Ktest_score[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "resident-phoenix",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2670\n",
      "[[('e y e m a s k', 'AY M AE S K'), ('A Y MAE S K', 'ア イ マ ス ク')], [('e s t a b l i s h m e n t', 'IH S T AE B L IH SH M AH N T'), ('IH S TAE B LIH SH MAH N T', 'イ ス タ ブ リッ シュ メ ン ト')], [('p o r c e l a i n', 'P AO R S AH L AH N'), ('PAO R SAH LAH N', 'ポ ー セ レ ン')], [('n o t c h', 'N AA CH'), ('NAA CH', 'ノッ チ')], [('h o s t i n g s e r v e r', 'HH OW S T IH NG S ER V ER'), ('HHO W S TIH N G SE R VE R', 'ホ ス ティ ン グ サ ー バ')], [('c o n d o r', 'K AA N D ER'), ('KAA N DE R', 'コ ン ド ル')], [('c u s t o m d i a l o g b o x', 'K AH S T AH M D AY AH L AO G B AA K S'), ('KAH S TAH M DA Y AH LAO G BAA K S', 'カ ス タ ム ダ イ ア ロ グ ボッ ク ス')], [('c h i n a r i s k', 'CH AY N AH R IH S K'), ('CHA Y NAH RIH S K', 'チャ イ ナ リ ス ク')], [('s c o r p i o n', 'S K AO R P IY AH N'), ('S KAO R PI Y AH N', 'ス コ ー ピ オ ン')], [('d a v i s c u p', 'D EY V AH S K AH P'), ('DE Y VAH S KAH P', 'デ ビ ス カッ プ')]]\n"
     ]
    }
   ],
   "source": [
    "keyss= list(zip(ec, mk))# this list contains pairs like this: ((english, CMU pron),(aligned pron, katakana))\n",
    "keys_w=[]\n",
    "for i in keyss:\n",
    "    ii=[]\n",
    "    ii.append(i[0])\n",
    "    ii.append(i[1])\n",
    "    keys_w.append(ii)\n",
    "print(len(keys_w))\n",
    "print(keys_w[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "extreme-sheep",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2124\n",
      "[('A Y MAE S K', 'ア イ マ ス ク'), ('IH S TAE B LIH SH MAH N T', 'イ ス タ ブ リッ シュ メ ン ト'), ('PAO R SAH LAH N', 'ポ ー セ レ ン'), ('NAA CH', 'ノッ チ'), ('HHO W S TIH N G SE R VE R', 'ホ ス ティ ン グ サ ー バ'), ('KAA N DE R', 'コ ン ド ル'), ('CHA Y NAH RIH S K', 'チャ イ ナ リ ス ク'), ('S KAO R PI Y AH N', 'ス コ ー ピ オ ン'), ('VA Y TAH MAH N', 'ヴィ タ ミ ン'), ('IH LEH K T RAA NIH K ME Y L', 'エ レ ク ト ロ ニッ ク メ ー ル')]\n"
     ]
    }
   ],
   "source": [
    "##### calculate the number of words that have correct phoneme translation\n",
    "\n",
    "pred_e=[]\n",
    "for i in keys_w:\n",
    "    if i[0] in cor_ph:\n",
    "        pred_e.append(i[1])\n",
    "print(len(pred_e)) \n",
    "print(pred_e[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "potential-cabinet",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "550\n",
      "2120\n",
      "['サ イ ド メ ニュ ー', 'シ ザ ー ス パ ス', 'フ ル ス ク ラッ チ', 'ス ワッ プ ファ イ ル', 'ポ ー ル ジャ ン プ', 'ポッ プ ブ ロッ カ ー', 'ス ワ ン ボ ー ト', 'ダ ル メ ー ショ ン', 'プ ラ イ バ シ', 'バ ー テ ン ダ ー']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pred_ew=[]\n",
    "nn=[]\n",
    "for i in pred_en:\n",
    "    if i[0] in pred_e:\n",
    "        pred_ew.append(i[1])\n",
    "    if i[0] not in pred_e:\n",
    "        nn.append(i)\n",
    "print(len(nn))\n",
    "print(len(pred_ew))\n",
    "print(pred_ew[:10])# predicted kata words that are correct at eng-phone level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "printable-premium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "856\n"
     ]
    }
   ],
   "source": [
    "notw1=[]\n",
    "for i in pred_ew:\n",
    "    if i not in ans1:\n",
    "        notw1.append(i)\n",
    "print(len(notw1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "saved-relay",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2120\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "pred_ew1=[]\n",
    "for i in pred_ew:\n",
    "    j=re.sub(\" \", \"\", i)\n",
    "    pred_ew1.append(j)\n",
    "print(len(pred_ew1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "finnish-solomon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26776\n"
     ]
    }
   ],
   "source": [
    "kat_w=[]\n",
    "with open(\"edict+cmu.tsv\", \"r\") as ejf:\n",
    "    for i in ejf:\n",
    "        l=i.rstrip().split(\"\\t\")\n",
    "        kat_w.append(l[0])\n",
    "print(len(kat_w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "interpreted-childhood",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "376\n",
      "['ダルメーション', 'ネーダーランド', 'ディコーディング', 'アシドシス', 'グラウティング', 'マソヒスティック', 'タイムラップス', 'ネビュライザー', 'アクイダクト', 'ダッチアイルス']\n"
     ]
    }
   ],
   "source": [
    "notw=[]\n",
    "for i in pred_ew1:\n",
    "    if i not in kat_w:\n",
    "        notw.append(i)\n",
    "print(len(notw))\n",
    "print(notw[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "endangered-globe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "val_s=list(zip(rescores, rescores1))\n",
    "both_cor=[]\n",
    "ph_cor=[]\n",
    "en_cor=[]\n",
    "for i in val_s:\n",
    "    if i[0]==0.0 and i[1]==0.0:\n",
    "        both_cor.append(i)\n",
    "    if i[0]==0.0 and i[1]!=0.0:\n",
    "        ph_cor.append(i)\n",
    "    if i[0]>0.0 and i[0] <=0.2 and i[1]==0.0:\n",
    "        en_cor.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "neutral-equity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1241\n",
      "883\n",
      "157\n"
     ]
    }
   ],
   "source": [
    "print(len(both_cor))\n",
    "print(len(ph_cor))\n",
    "print(len(en_cor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "horizontal-direction",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "combd=list(zip(keys_w, val_s))\n",
    "dec_ten=[]\n",
    "dec_nine=[]\n",
    "dec_eight=[]\n",
    "dec_seven=[]\n",
    "dec_six=[]\n",
    "comb_wer=[]\n",
    "for i in combd:\n",
    "    k= (i[1][0]+i[1][1])/2\n",
    "    if k==0.0:\n",
    "        dec_ten.append(i)\n",
    "    if k>0.0 and k<=0.1:\n",
    "        dec_nine.append(i)\n",
    "    if k>0.1 and k<=0.2:\n",
    "        dec_eight.append(i)\n",
    "    if k>0.2 and k<=0.3:\n",
    "        dec_seven.append(i)\n",
    "    if k>0.3 and k<=0.4:\n",
    "        dec_six.append(i)\n",
    "    comb_wer.append(k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "confident-africa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1241\n",
      "554\n",
      "463\n",
      "220\n",
      "101\n"
     ]
    }
   ],
   "source": [
    "print(len(dec_ten))\n",
    "print(len(dec_nine))\n",
    "print(len(dec_eight))\n",
    "print(len(dec_seven))\n",
    "print(len(dec_six))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "elect-surrey",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09463857677902607\n"
     ]
    }
   ],
   "source": [
    "ave_wer3= sum(comb_wer)/len(comb_wer)\n",
    "print(ave_wer3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "social-price",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.905\n"
     ]
    }
   ],
   "source": [
    "print(1-0.095)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "driving-david",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "298\n"
     ]
    }
   ],
   "source": [
    "print(1823-1525)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subjective-scale",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
